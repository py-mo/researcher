# 🧠 Researcher

A research assistant powered by LLMs + embeddings for **semantic document search**, **contextual Q&A**, and **automated knowledge extraction**.

> Your personal research assistant — manage papers, take notes, track projects, and search smarter.

---

## ✨ Features

- 🔍 Embedding-based semantic search (Nomic, Ollama, etc.)
- 🧠 LLM-powered context-aware Q&A
- 📄 PDF/document ingestion
- 📚 Designed for academic + deep research workflows

---

## 🛠️ Tech Stack

| Layer       | Tools |
|-------------|-------|
| Backend    | Python, LangChain |
| LLMs       | OpenAI API, Ollama |

---

## ⚡️ Motivation

As a CS student with a passion for AI and deep learning, I often read papers and documents. Traditional search is frustrating and inefficient when I need **context-aware** understanding or exploration.

**Goal:** Build a fast, local tool that helps me extract knowledge from documents through semantic search and LLMs.

---

## 🙋‍♂️ About Me
I'm Morteza, a computer science student and AI enthusiast.
This project is part of my journey into LLMs, retrieval-augmented generation, and building autonomous research tools.

> If you're interested in collaborating or sharing ideas, feel free to open an issue or contact me!
