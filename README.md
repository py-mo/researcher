# ðŸ§  Researcher

A research assistant powered by LLMs + embeddings for **semantic document search**, **contextual Q&A**, and **automated knowledge extraction**.

> Your personal research assistant â€” manage papers, take notes, track projects, and search smarter.

---

## âœ¨ Features

- ðŸ” Embedding-based semantic search (Nomic, Ollama, etc.)
- ðŸ§  LLM-powered context-aware Q&A
- ðŸ“„ PDF/document ingestion
- ðŸ“š Designed for academic + deep research workflows

---

## ðŸ› ï¸ Tech Stack

| Layer       | Tools |
|-------------|-------|
| Backend    | Python, LangChain |
| LLMs       | OpenAI API, Ollama |

---

## âš¡ï¸ Motivation

As a CS student with a passion for AI and deep learning, I often read papers and documents. Traditional search is frustrating and inefficient when I need **context-aware** understanding or exploration.

**Goal:** Build a fast, local tool that helps me extract knowledge from documents through semantic search and LLMs.

---

## Why Paused

Main reason: Focus has shifted to a [Hybrid-Retrieval-Augmented-Generation](https://github.com/py-mo/Hybrid-Retrieval-Augmented-Generation) that explores retrieval quality and advanced tooling.  
This project is on hold until insights and components from that work can be merged back.


---

## ðŸ™‹â€â™‚ï¸ About Me

I'm Morteza, a computer science student and AI enthusiast.
This project is part of my journey into LLMs, retrieval-augmented generation, and building autonomous research tools.

> If you're interested in collaborating or sharing ideas, feel free to open an issue or contact me!
